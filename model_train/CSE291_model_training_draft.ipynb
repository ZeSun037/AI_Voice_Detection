{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcNNs3WzD1Iz"
   },
   "outputs": [],
   "source": [
    "# imports -----------------------------------------------------------------\n",
    "import torchvision.transforms as T_vision\n",
    "import librosa\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETqePp5cExuZ"
   },
   "outputs": [],
   "source": [
    "# organize directories ----------------------------------------------------\n",
    "# stores train/val fricative waveform files for all sentences and speakers\n",
    "ai_wav_dir = '/content/data/ai_wav/'\n",
    "real_wav_dir = '/content/data/real_wav/'\n",
    "\n",
    "# stores train/val fricative spectrograms for all sentences and speakers\n",
    "ai_spect_dir = '/content/data/ai_spect/'\n",
    "real_spect_dir = '/content/data/real_spect/'\n",
    "\n",
    "# stores train/val fricative spectrograms for all sentences and speakers\n",
    "ai_spect_dir = '/content/data/ai_spect/'\n",
    "real_spect_dir = '/content/data/real_spect/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMDc2yvapCEp"
   },
   "outputs": [],
   "source": [
    "# TODO: probably should move all this to preproc.py\n",
    "# helper functions --------------------------------------------------------\n",
    "def normalize_to_img(spect):\n",
    "  '''\n",
    "  this function normalizes all values in spectrogram to 0-255\n",
    "    INPUTS\n",
    "      spect   : spectrogram\n",
    "    OUTPUTS\n",
    "      normalized spect\n",
    "  '''\n",
    "  return (spect - spect.min()) / (spect.max() - spect.min()) *255\n",
    "\n",
    "def get_spectrograms(wav_dir, spect_dir, label):\n",
    "  '''\n",
    "  this function creates mel spectrogram in db for all waveforms in a folder\n",
    "    INPUTS\n",
    "      wav_dir   : directory name of waveforms\n",
    "      spect_dir : directory name of where to store spectrograms\n",
    "      label     : 0 - real or 1 - AI\n",
    "    OUTPUTS\n",
    "      none\n",
    "  '''\n",
    "  for idx, wav in enumerate(list(os.listdir(wav_dir))):\n",
    "    y, sr = librosa.load(wav_dir + wav)\n",
    "\n",
    "    spect = librosa.feature.melspectrogram(y,sr)\n",
    "    spect = librosa.amplitude_to_db(spect)\n",
    "\n",
    "    # remove single-dimension, normalize to pixel val 0-255, typecast to uint8\n",
    "    spect_img = normalize_to_img(spect.squeeze().np()).astype(np.uint8)\n",
    "    # flip to correct y-axis, frequencies from low -> high\n",
    "    spect_img = np.flip(spect_img)\n",
    "    # invert pixels s.t. more energy is represented by darker pixels\n",
    "    spect_img = 255-spect_img\n",
    "\n",
    "    im = Image.fromarray(spect_img)\n",
    "    # TODO: should we be more specific with the naming? like sentence number\n",
    "    # and speaker number?\n",
    "    fname = spect_dir + f\"{label}_{idx}\"\n",
    "    im.save(fname)\n",
    "    # TODO: if this takes a super long time, should we just be saving data as\n",
    "    # matrix data?\n",
    "\n",
    "\n",
    "# prep data ---------------------------------------------------------------\n",
    "get_spectrograms(ai_wav_dir,ai_spect_dir, 1)\n",
    "get_spectrograms(real_wav_dir, real_spect_dir, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExhNJXfmGAit"
   },
   "outputs": [],
   "source": [
    "# TODO: dataset class and dataloader\n",
    "# split train/val sets ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-q7hfrQuEzzO"
   },
   "outputs": [],
   "source": [
    "# CUDA --------------------------------------------------------------------\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('**setup note** using device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgR76OHKE0D0"
   },
   "outputs": [],
   "source": [
    "# CNN model ---------------------------------------------------------------\n",
    "#   1. conv ReLU\n",
    "#   2. maxpooling, dropout 50%\n",
    "#   3. conv ReLU\n",
    "#   4. maxpooling\n",
    "#   5. FC ReLU, dropout 50%\n",
    "#   6. FC ReLU, dropout 50%\n",
    "#   7. softmax\n",
    "class TwoLayerCNN(nn.Module):\n",
    "  def __init__(self, c1, c2, c3):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=c1, out_channels=c2, kernel_size=3, stride=1, padding=0)\n",
    "    self.conv2 = nn.Conv2d(in_channels=c2, out_channels=c3, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "    self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    self.maxPool1 = nn.MaxPool2d((4,3), stride=(1,3))\n",
    "    self.maxPool2 = nn.MaxPool2d((1,3), stride=(1,3))\n",
    "\n",
    "    self.fc1 = nn.Linear(in_features=5000, out_features=2)\n",
    "    self.fc2 = nn.Linear(in_features=5000, out_features=2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    scores = None\n",
    "    x = self.relu(self.conv_2(self.relu(self.conv_1(x))))\n",
    "    x = nn.Flatten(x)\n",
    "    scores = self.fc1(x)\n",
    "    return scores\n",
    "  \n",
    "  \n",
    "def validate(model, device, val_loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for input, target in val_loader:\n",
    "      input = input.to(device)\n",
    "      target = target.to(device)\n",
    "\n",
    "      output = model(input)\n",
    "      _, prediction = output.max(axis=1)\n",
    "      correct += (prediction == target).sum()\n",
    "      total += prediction.size(0)\n",
    "\n",
    "    accuracy = float(correct)/total\n",
    "  \n",
    "  return accuracy\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, val_loader, lr, m, wd, epochs,\n",
    "           print = 100):\n",
    "  loss_curve = []\n",
    "  acc_curve = []\n",
    "\n",
    "  model = model.to(device)\n",
    "  model.train()\n",
    "  optimizer = optim.SGD(model.parameters(), lr=lr, momentum=m,\n",
    "                         weight_decay=wd, nesterov=True)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    for iter, (input, target) in enumerate(train_loader):\n",
    "      input = input.to(device)\n",
    "      target = target.to(device)\n",
    "\n",
    "      output = model(input)\n",
    "      loss = nn.functional.cross_entropy(output, target)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      loss_curve.append(loss.item())\n",
    "\n",
    "      # TODO: can move to print block if too slow        \n",
    "      accuracy = validate(model, device, val_loader)\n",
    "      acc_curve.append(accuracy)\n",
    "\n",
    "\n",
    "      if (i+1) % print == 0:\n",
    "        print(f'Running Epoch {epoch} and Iteration {iter}: Loss is {loss.item()}')\n",
    "\n",
    "        print(f'Accuracy against validation set is {accuracy}')\n",
    "\n",
    "  return loss_curve, acc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 1\n",
    "channel1 = 512\n",
    "channel2 = 1024\n",
    "num_classes = 2\n",
    "lr = 0.002\n",
    "m = 0.9\n",
    "wd = 0.001\n",
    "epochs = 300\n",
    "\n",
    "model = TwoLayerCNN(layers, channel1, channel2, num_classes)\n",
    "loss_curve, acc_curve = train(model, device, train_loader, val_loader, lr, m, wd, epochs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ece176",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
